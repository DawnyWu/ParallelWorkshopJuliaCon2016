{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel programming constructs in Base Julia\n",
    "\n",
    "- Example used\n",
    "    - calculate pi using random numbers (circle circumscribed by a square)\n",
    "    - Area of circle / Area of square = pi / 4\n",
    "\n",
    "- Processes vs tasks\n",
    "    - Process\n",
    "        - Single thread of execution scheduled by the OS\n",
    "        - Master process\n",
    "            - Driver, orchestrates work\n",
    "            - Hosts the REPL in interactive mode, or the main script in non-interactive mode  \n",
    "        - Workers\n",
    "            - Different OS processes, typically one per core\n",
    "        - Identified by a numeric process id, not related to the OS pid\n",
    "    - Tasks are lightweight co-routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First the serial version\n",
    "function serial_π(n)\n",
    "    in_circle = 0 \n",
    "    for i in 1:n\n",
    "        x = rand()\n",
    "        y = rand()\n",
    "        in_circle += Int((x^2 + y^2) < 1.0)\n",
    "    end\n",
    "    return (in_circle/n) * 4.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"π = \", @time serial_π(10^8) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute in parallel\n",
    "- First set up a local cluster\n",
    "- Master process + Worker processes \n",
    "- Workers may be on the same host, or different hosts\n",
    "- Workers can be launched on cluster managers like SGE, SLURM, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if nprocs() == 1\n",
    "    addprocs(4)\n",
    "end\n",
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "procs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the serial version to execute the for loop in parallel\n",
    "    - Use @parallel for\n",
    "    - Partitions a \"for\" loop\n",
    "    - Equally partitioned among available workers\n",
    "    - Can specify a reduction operator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Parallel version\n",
    "function parallel_π(n)\n",
    "    in_circle = @parallel (+) for i in 1:n       # <----- partition work\n",
    "        x = rand()\n",
    "        y = rand()\n",
    "        Int((x^2 + y^2) < 1.0)\n",
    "    end\n",
    "    return (in_circle/n) * 4.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"π = \", @time parallel_π(10^8) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Julia Tasks\n",
    "\n",
    "- What is a Julia Task?\n",
    "    - very lightweight coroutines\n",
    "    - Not threads!\n",
    "    - Internal to and scheduled by a Julia Process\n",
    "    - Runs till it performs an I/O operation or explictly yields (calls sleep() or yield() )\n",
    "    - A non-yielding task in a process prevents any other code from execution (including I/O operations)\n",
    "    - Julia process driving external services in parallel\n",
    "    - Julia master driving worker processes in a Julia cluster \n",
    "\n",
    "\n",
    "Simple example of a single Julia process driving a few external resources\n",
    "    - Calculate pi using all the machines available at JuliaCon \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pseudo-code (driver)\n",
    "\n",
    "```\n",
    "schedule a background task to\n",
    "    listen on a known port\n",
    "    while true\n",
    "       accept and store incoming connections from machines at JuliaCon\n",
    "    end\n",
    "       \n",
    "    \n",
    "function calculate_pi_in_parallel\n",
    "    send out computation requests to all connected machines\n",
    "    add each response to a queue as it arrives\n",
    "    process responses as they arrive till all responses have been recd or a timeout\n",
    "    \n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pseudo-code (calculation service)\n",
    "\n",
    "```\n",
    "connect to orchestrator\n",
    "while true\n",
    "  wait for a request\n",
    "  compute request in parallel locally\n",
    "  send back the response\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Driver code for reference\n",
    "\n",
    "```\n",
    "# Calculate pi using all instances of the users at JuliaCon\n",
    "\n",
    "const clients=Set()\n",
    "\n",
    "@schedule begin\n",
    "    srvr = listen(8000)\n",
    "    while true\n",
    "        sock = accept(srvr)\n",
    "        push!(clients, sock)\n",
    "    end\n",
    "end\n",
    "\n",
    "function calc_π(n_each)\n",
    "    println(\"Processing remotely on possible $(length(clients)) clients\")\n",
    "\n",
    "    # This function will wait for a maximum of 10.0 seconds for clients to return\n",
    "    tc = Condition()\n",
    "    t0 = time()\n",
    "    @schedule (sleep(10.0); notify(tc))     # <---- exit the wait in time\n",
    "    \n",
    "    response_channel = Channel()\n",
    "    for c in clients\n",
    "        if isopen(c)\n",
    "            @async try                      # <---- execute remotely in parallel\n",
    "                serialize(c, n_each)\n",
    "                put!(response_channel, deserialize(c))\n",
    "                notify(tc)\n",
    "            catch e\n",
    "                delete!(clients, c)\n",
    "            end\n",
    "        else \n",
    "            delete!(clients, c)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    incircle = 0\n",
    "    nclients = 0\n",
    "    \n",
    "    # wait for all responses or the timeout\n",
    "    while true\n",
    "        nclients == length(clients) && break     # Have processed all clients\n",
    "        \n",
    "        !isready(response_channel) && wait(tc)   # Block wait for a pending response or a timeout\n",
    "                                      \n",
    "        !isready(response_channel) && break      # Still not ready, indicates a timeout\n",
    "        \n",
    "        incircle += take!(response_channel)\n",
    "        nclients += 1\n",
    "        \n",
    "        println(\"pi calculated from $nclients workers = \", 4*incircle/(nclients*n_each))\n",
    "        \n",
    "    end\n",
    "    4*incircle/(nclients*n_each)\n",
    "        \n",
    "end\n",
    "\n",
    "calc_π(10^6)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Make available your local computation resources\n",
    "##################################################\n",
    "@schedule begin\n",
    "    c = connect(\"107.23.255.102\", 8000)\n",
    "    while true\n",
    "        num_points = deserialize(c)    # <---- wait for a request    \n",
    "        \n",
    "        in_circle = @parallel (+) for i in 1:num_points\n",
    "            Int(rand()^2 + rand()^2 < 1)\n",
    "        end\n",
    "        \n",
    "        println(\"Received request for $num_points points. Response $in_circle\")\n",
    "        serialize(c, in_circle)        # <---- send back response\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Julia Tasks and Workers together\n",
    "\n",
    "Let us build a simple distributed vector\n",
    "- architecturally similar to DistributedArrays.jl\n",
    "- create a distributed vector of random floats and implement a map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "nprocs() == 1 && addprocs(4)\n",
    "\n",
    "type DVector\n",
    "    refs::Array{RemoteRef}  # references to localparts\n",
    "    cuts::Array{UnitRange{Int}}    # cut of vector on ith worker\n",
    "    pids::Array{Int}        # participating workers, refs[i] is on pids[i]\n",
    "    \n",
    "    function DVector(N)\n",
    "        refs=[]\n",
    "        cuts=[]\n",
    "        pids=workers()\n",
    "        localpart_len = div(N, nworkers())\n",
    "        ncut_start = 1\n",
    "        for p in pids\n",
    "            if p == pids[end]\n",
    "                localpart_len = localpart_len + rem(N, nworkers())\n",
    "            end\n",
    "            push!(refs, remotecall(p, rand, localpart_len))     # create the localpart on each worker\n",
    "                                                                # and hold a reference to it\n",
    "            \n",
    "            push!(cuts, ncut_start:ncut_start+localpart_len-1)  # Which worker has which part\n",
    "            ncut_start += localpart_len\n",
    "        end\n",
    "        return new(refs, cuts, workers())\n",
    "    end\n",
    "end\n",
    "\n",
    "function Base.convert(::Type{Array}, d::DVector)\n",
    "    A = Array(Float64, last(d.cuts[end]))\n",
    "    @sync for (i,r) in enumerate(d.refs)  # wait for all enclosed requests to finish\n",
    "        @async A[d.cuts[i]] = fetch(r)    # perform the \"fetching\" in parallel\n",
    "    end\n",
    "    A\n",
    "end\n",
    "\n",
    "function Base.getindex(d::DVector, i)\n",
    "    idx = findfirst(x -> i in x, d.cuts)  # Locate which ref has the index we need\n",
    "\n",
    "    # fetch only the single element. fetch localpart on correct worker and index locally. \n",
    "    remotecall_fetch(d.pids[idx], (li, r) -> fetch(r)[li], i-first(d.cuts[idx])+1, d.refs[idx])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d=DVector(12)   # As you can see the local structure only has refernces to distributed parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# gather distributed parts\n",
    "Array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement a distributed map\n",
    "function Base.map!(f, d::DVector)\n",
    "    @sync for (i, p) in enumerate(d.pids)\n",
    "        @async remotecall_wait(p, (f,r)->(map!(f, fetch(r)); nothing), f, d.refs[i])\n",
    "    end\n",
    "    d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets try it out \n",
    "map!(x->1.0, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gather parts and display\n",
    "Array(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Package DistributedArrays.jl has the complete implementation for distributed arrays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
